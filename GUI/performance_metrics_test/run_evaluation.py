#!/usr/bin/env python3
"""
Quick runner script to evaluate Random Forest model performance
"""

import os
import time

def main():
    """Run the model evaluation"""
    
    print("üçé FOOD RECOMMENDATION SYSTEM - MODEL PERFORMANCE EVALUATION")
    print("=" * 70)
    print()
    
    # Check if the required files exist
    required_files = [
        'food_recommendation_system_using_rf_model_v2.py',
        'datasets'  # datasets folder
    ]
    
    missing_files = []
    for file in required_files:
        if not os.path.exists(file):
            missing_files.append(file)
    
    if missing_files:
        print("‚ùå Missing required files/folders:")
        for file in missing_files:
            print(f"   - {file}")
        print("\nüí° Please ensure all required files are in the current directory")
        return
    
    # Import and run the evaluation
    try:
        # Import the evaluation system
        from model_performance_evaluator import evaluate_random_forest_system
        
        print("üöÄ Starting Random Forest Model Evaluation...")
        print()
        
        start_time = time.time()
        
        # Run the evaluation
        results = evaluate_random_forest_system()
        
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        if results:
            print(f"\n‚è±Ô∏è  Evaluation completed in {elapsed_time:.2f} seconds")
            
            # Quick summary display
            print("\n" + "="*70)
            print("üìã QUICK PERFORMANCE SUMMARY")
            print("="*70)
            
            if 'Random_Forest' in results:
                rf_data = results['Random_Forest']
                
                # Overall performance metrics
                if 'overall_performance' in rf_data:
                    overall = rf_data['overall_performance']
                    
                    print("\nüîç REGRESSION METRICS:")
                    print(f"   ‚Ä¢ Average R¬≤ Score: {overall.get('avg_r2_score', 0):.4f}")
                    print(f"   ‚Ä¢ Average MSE: {overall.get('avg_mse', 0):.4f}")
                    print(f"   ‚Ä¢ Average RMSE: {overall.get('avg_rmse', 0):.4f}")
                    print(f"   ‚Ä¢ Average MAE: {overall.get('avg_mae', 0):.4f}")
                    
                    print("\nüéØ CLASSIFICATION METRICS:")
                    print(f"   ‚Ä¢ Average Accuracy: {overall.get('avg_accuracy', 0):.4f}")
                    print(f"   ‚Ä¢ Average Precision: {overall.get('avg_precision', 0):.4f}")
                    print(f"   ‚Ä¢ Average Recall: {overall.get('avg_recall', 0):.4f}")
                    print(f"   ‚Ä¢ Average F1-Score: {overall.get('avg_f1_score', 0):.4f}")
                    
                    print("\nüè• HEALTH-AWARE METRICS:")
                    print(f"   ‚Ä¢ Health Alignment Score: {overall.get('avg_health_alignment_score', 0):.4f}")
                    print(f"   ‚Ä¢ Condition Specificity: {overall.get('avg_condition_specificity', 0):.4f}")
                    print(f"   ‚Ä¢ Nutritional Quality: {overall.get('avg_nutritional_diversity', 0):.4f}")
                    print(f"   ‚Ä¢ Dietary Safety Score: {overall.get('avg_dietary_safety_score', 0):.4f}")
                    print(f"   ‚Ä¢ Personalization Effectiveness: {overall.get('avg_personalization_effectiveness', 0):.4f}")
                    
                    print("\nüåü RECOMMENDATION QUALITY:")
                    print(f"   ‚Ä¢ Diversity Score: {overall.get('avg_diversity_score', 0):.4f}")
                    print(f"   ‚Ä¢ Novelty Score: {overall.get('avg_novelty_score', 0):.4f}")
                    print(f"   ‚Ä¢ Coverage Score: {overall.get('avg_coverage_score', 0):.4f}")
                    print(f"   ‚Ä¢ User Satisfaction Estimate: {overall.get('avg_user_satisfaction_estimate', 0):.4f}")
                    print(f"   ‚Ä¢ Catalog Coverage: {overall.get('avg_catalog_coverage', 0):.4f}")
                
                # Recommendation system performance
                if 'recommendation_accuracy' in rf_data:
                    rec_acc = rf_data['recommendation_accuracy']
                    if 'error' not in rec_acc:
                        print("\nüçΩÔ∏è  RECOMMENDATION SYSTEM PERFORMANCE:")
                        print(f"   ‚Ä¢ Total Recommendations Generated: {rec_acc.get('total_recommendations', 0)}")
                        print(f"   ‚Ä¢ Suitable Recommendations: {rec_acc.get('suitable_recommendations', 0)}")
                        print(f"   ‚Ä¢ Suitability Rate: {rec_acc.get('suitability_rate', 0):.4f}")
                        print(f"   ‚Ä¢ Condition Match Rate: {rec_acc.get('condition_match_rate', 0):.4f}")
                        print(f"   ‚Ä¢ Average Recommendation Score: {rec_acc.get('avg_recommendation_score', 0):.4f}")
                        print(f"   ‚Ä¢ Top 5 Average Score: {rec_acc.get('top_5_avg_score', 0):.4f}")
                
                # Top features
                if 'feature_importance' in rf_data:
                    print("\n‚≠ê TOP 5 MOST IMPORTANT FEATURES:")
                    for i, (feature, importance) in enumerate(list(rf_data['feature_importance'].items())[:5]):
                        print(f"   {i+1}. {feature}: {importance:.4f}")
                
                # Individual model performance
                if 'individual_models' in rf_data:
                    print("\nüìä INDIVIDUAL MODEL PERFORMANCE:")
                    for model_name, metrics in rf_data['individual_models'].items():
                        print(f"\n   {model_name.replace('_', ' ')}:")
                        print(f"      R¬≤ Score: {metrics.get('r2_score', 0):.4f}")
                        print(f"      Accuracy: {metrics.get('accuracy', 0):.4f}")
                        print(f"      F1-Score: {metrics.get('f1_score', 0):.4f}")
            
            print("\nüìÑ Files Generated:")
            print("   ‚Ä¢ random_forest_performance_report.txt - Detailed performance report")
            print("   ‚Ä¢ random_forest_performance_plots.png - Performance visualization plots")
            
            print("\nüîÆ Framework Features:")
            print("   ‚Ä¢ ‚úÖ Random Forest evaluation complete")
            print("   ‚Ä¢ üîÑ Ready to add K-NN evaluation")
            print("   ‚Ä¢ üîÑ Ready to add XGBoost evaluation")
            print("   ‚Ä¢ üîÑ Ready for side-by-side model comparison")
            
            print("\n‚úÖ Evaluation completed successfully!")
            
        else:
            print("‚ùå Evaluation failed!")
            
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        print("üí° Make sure all required Python packages are installed:")
        print("   pip install pandas numpy matplotlib seaborn scikit-learn")
        
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")


if __name__ == "__main__":
    main()
